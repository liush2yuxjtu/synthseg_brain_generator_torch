"""TensorFlow implementation of lab2im model

If you use this code, please cite the first SynthSeg paper:
https://github.com/BBillot/lab2im/blob/master/bibtex.bib

Copyright 2020 Benjamin Billot

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in
compliance with the License. You may obtain a copy of the License at
https://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software distributed under the License is
distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
implied. See the License for the specific language governing permissions and limitations under the
License.
"""


# python imports
import numpy as np
import keras.layers as KL
from keras.models import Model

# project imports
from ext.lab2im import utils
from ext.lab2im import layers_tf
from ext.lab2im.edit_tensors import resample_tensor_tf, blurring_sigma_for_downsampling_tf


def lab2im_model_tf(labels_shape,
                 n_channels,
                 generation_labels,
                 output_labels,
                 atlas_res,
                 target_res,
                 output_shape=None,
                 output_div_by_n=None,
                 blur_range=1.15):
    """
    This function builds a keras/tensorflow model to generate images from provided label maps.
    The images are generated by sampling a Gaussian Mixture Model (of given parameters), conditioned on the label map.
    The model will take as inputs:
        -a label map
        -a vector containing the means of the Gaussian Mixture Model for each label,
        -a vector containing the standard deviations of the Gaussian Mixture Model for each label,
        -an array of size batch*(n_dims+1)*(n_dims+1) representing a linear transformation
    The model returns:
        -the generated image normalised between 0 and 1.
        -the corresponding label map, with only the labels present in output_labels (the other are reset to zero).
    :param labels_shape: shape of the input label maps. Can be a sequence or a 1d numpy array.
    :param n_channels: number of channels to be synthetised.
    :param generation_labels: list of all possible label values in the input label maps.
    Can be a sequence or a 1d numpy array.
    :param output_labels: list of the same length as generation_labels to indicate which values to use in the label maps
    returned by this model, i.e. all occurrences of generation_labels[i] in the input label maps will be converted to
    output_labels[i] in the returned label maps. Examples:
    Set output_labels[i] to zero if you wish to erase the value generation_labels[i] from the returned label maps.
    Set output_labels[i]=generation_labels[i] if you wish to keep the value generation_labels[i] in the returned maps.
    Can be a list or a 1d numpy array. By default output_labels is equal to generation_labels.
    :param atlas_res: resolution of the input label maps.
    Can be a number (isotropic resolution), a sequence, or a 1d numpy array.
    :param target_res: target resolution of the generated images and corresponding label maps.
    Can be a number (isotropic resolution), a sequence, or a 1d numpy array.
    :param output_shape: (optional) desired shape of the output images.
    If the atlas and target resolutions are the same, the output will be cropped to output_shape, and if the two
    resolutions are different, the output will be resized with trilinear interpolation to output_shape.
    Can be an integer (same size in all dimensions), a sequence, or a 1d numpy array.
    :param output_div_by_n: (optional) forces the output shape to be divisible by this value. It overwrites output_shape
    if necessary. Can be an integer (same size in all dimensions), a sequence, or a 1d numpy array.
    :param blur_range: (optional) Randomise the standard deviation of the blurring kernels, (whether data_res is given
    or not). At each mini_batch, the standard deviation of the blurring kernels are multiplied by a coefficient sampled
    from a uniform distribution with bounds [1/blur_range, blur_range]. If None, no randomisation. Default is 1.15.
    """

    # reformat resolutions
    labels_shape = utils.reformat_to_list(labels_shape)
    n_dims, _ = utils.get_dims(labels_shape)
    atlas_res = utils.reformat_to_n_channels_array(atlas_res, n_dims=n_dims)[0]
    target_res = atlas_res if (target_res is None) else utils.reformat_to_n_channels_array(target_res, n_dims)[0]

    # get shapes
    crop_shape, output_shape = get_shapes_tf(labels_shape, output_shape, atlas_res, target_res, output_div_by_n)

    # define model inputs
    labels_input = KL.Input(shape=labels_shape+[1], name='labels_input', dtype='int32')
    means_input = KL.Input(shape=list(generation_labels.shape) + [n_channels], name='means_input')
    stds_input = KL.Input(shape=list(generation_labels.shape) + [n_channels], name='stds_input')

    # deform labels
    labels = layers_tf.RandomSpatialDeformation(inter_method='nearest')(labels_input)

    # cropping
    if crop_shape != labels_shape:
        labels._keras_shape = tuple(labels.get_shape().as_list())
        labels = layers_tf.RandomCrop(crop_shape)(labels)

    # build synthetic image
    labels._keras_shape = tuple(labels.get_shape().as_list())
    image = layers_tf.SampleConditionalGMM(generation_labels)([labels, means_input, stds_input])

    # apply bias field
    image._keras_shape = tuple(image.get_shape().as_list())
    image = layers_tf.BiasFieldCorruption()(image)

    # intensity augmentation
    image._keras_shape = tuple(image.get_shape().as_list())
    image = layers_tf.IntensityAugmentation()(image)

    # reset label values
    labels._keras_shape = tuple(labels.get_shape().as_list())
    labels = layers_tf.ConvertLabels(generation_labels, output_labels)(labels)

    # get data at target resolution (resampling and cropping)
    if atlas_res.tolist() != target_res.tolist():

        # get resampling factor
        if atlas_res.tolist() != target_res.tolist():
            factor = np.array(atlas_res) / np.array(target_res)
        else:
            factor = None

        # resample image and labels at target resolution
        if factor is not None:
            image._keras_shape = tuple(image.get_shape().as_list())
            image = layers_tf.DynamicGaussianBlur(blur_range)(image)
            image._keras_shape = tuple(image.get_shape().as_list())
            image = layers_tf.MimicAcquisition(atlas_res, target_res)(image)
            labels._keras_shape = tuple(labels.get_shape().as_list())
            labels = layers_tf.ResizeTransform(factor, interp_method='nearest')(labels)

        # crop image and labels at target shape
        if output_shape != labels._keras_shape[1:-1]:
            image._keras_shape = tuple(image.get_shape().as_list())
            image = layers_tf.RandomCrop(output_shape)(image)
            labels._keras_shape = tuple(labels.get_shape().as_list())
            labels = layers_tf.RandomCrop(output_shape)(labels)

    # normalise image
    image._keras_shape = tuple(image.get_shape().as_list())
    image = layers_tf.IntensityNormalisation()(image)

    return Model(inputs=[labels_input, means_input, stds_input], outputs=[image, labels])


def get_shapes_tf(labels_shape, output_shape, atlas_res, target_res, output_div_by_n):
    """Compute the shape of the input and output tensors that will be given to the neural network.
    This assumes that the inputs of the network will be cropped to a given shape, and the outputs will be resized to
    another given shape.
    :param labels_shape: shape of the input label maps, without batch or channel dimensions.
    :param output_shape: shape of the outputs, without batch or channel dimensions.
    Can be an int, a sequence or a 1d numpy array.
    :param atlas_res: resolution of the input label maps.
    :param target_res: resolution of the outputs.
    :param output_div_by_n: (optional) forces the output shape to be divisible by this value. It overwrites output_shape
    if necessary. Can be an int, a sequence or a 1d numpy array.
    :return: a list with two items: the shape of the cropped inputs, and the shape of the outputs.
    """

    # get cropping shape
    n_dims = len(labels_shape)
    labels_shape = utils.reformat_to_list(labels_shape, length=n_dims)
    atlas_res = utils.reformat_to_list(atlas_res, length=n_dims)
    target_res = utils.reformat_to_list(target_res, length=n_dims)
    crop_shape = labels_shape

    # get output shape
    if output_shape is not None:  # in this case output_shape overwrites target_res
        output_shape = utils.reformat_to_list(output_shape, length=n_dims)
    elif atlas_res != target_res:  # here we use target_res to compute the output shape
        output_shape = [int(labels_shape[i] * atlas_res[i] / target_res[i]) for i in range(n_dims)]
    else:  # if we don't resize the inputs, the outputs will have the same shape as the cropped inputs
        output_shape = crop_shape

    # make sure output shape is divisible by output_div_by_n
    if output_div_by_n is not None:
        output_div_by_n = utils.reformat_to_list(output_div_by_n, length=n_dims)
        tmp_shape = [utils.find_closest_number_divisible_by_m(s, output_div_by_n[i], smaller_ans=False)
                     for (i, s) in enumerate(output_shape)]
        if output_shape != tmp_shape:
            print('output shape {0} not divisible by {1}, changed to {2}'.format(output_shape, output_div_by_n,
                                                                                 tmp_shape))
            output_shape = tmp_shape

    return crop_shape, output_shape