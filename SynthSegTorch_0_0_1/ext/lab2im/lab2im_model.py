"""PyTorch implementation of lab2im model

If you use this code, please cite the first SynthSeg paper:
https://github.com/BBillot/lab2im/blob/master/bibtex.bib

Copyright 2020 Benjamin Billot

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in
compliance with the License. You may obtain a copy of the License at
https://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, software distributed under the License is
distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
implied. See the License for the specific language governing permissions and limitations under the
License.
"""


# python imports
import torch
import torch.nn as nn
import numpy as np

# project imports
from ext.lab2im import utils
from ext.lab2im import layers
from ext.lab2im.edit_tensors import resample_tensor, blurring_sigma_for_downsampling


class Lab2ImModel(nn.Module):
    """PyTorch model to generate images from provided label maps.
    
    The images are generated by sampling a Gaussian Mixture Model (of given parameters), conditioned on the label map.
    """
    
    def __init__(self,
                 labels_shape,
                 n_channels,
                 generation_labels,
                 output_labels,
                 atlas_res,
                 target_res,
                 output_shape=None,
                 output_div_by_n=None,
                 blur_range=1.15):
        """Initialize the Lab2ImModel.
        
        Args:
            labels_shape: shape of the input label maps. Can be a sequence or a 1d numpy array.
            n_channels: number of channels to be synthesized.
            generation_labels: list of all possible label values in the input label maps.
                Can be a sequence or a 1d numpy array.
            output_labels: list of the same length as generation_labels to indicate which values to use in the label maps
                returned by this model.
            atlas_res: resolution of the input label maps.
                Can be a number (isotropic resolution), a sequence, or a 1d numpy array.
            target_res: target resolution of the generated images and corresponding label maps.
                Can be a number (isotropic resolution), a sequence, or a 1d numpy array.
            output_shape: (optional) desired shape of the output images.
            output_div_by_n: (optional) forces the output shape to be divisible by this value.
            blur_range: (optional) Randomize the standard deviation of the blurring kernels.
        """
        super(Lab2ImModel, self).__init__()
        
        # Store parameters
        self.labels_shape = labels_shape
        self.n_channels = n_channels
        self.generation_labels = generation_labels
        self.output_labels = output_labels
        self.atlas_res = atlas_res
        self.target_res = target_res
        self.output_shape = output_shape
        self.output_div_by_n = output_div_by_n
        self.blur_range = blur_range
        
        # Reformat resolutions
        self.labels_shape = utils.reformat_to_list(self.labels_shape)
        self.n_dims, _ = utils.get_dims(self.labels_shape)
        self.atlas_res = utils.reformat_to_n_channels_array(self.atlas_res, n_dims=self.n_dims)[0]
        self.target_res = self.atlas_res if (self.target_res is None) else \
            utils.reformat_to_n_channels_array(self.target_res, self.n_dims)[0]
        
        # Get shapes
        self.crop_shape, self.output_shape = get_shapes(self.labels_shape, self.output_shape, 
                                                       self.atlas_res, self.target_res, self.output_div_by_n)
        
        # Initialize layers
        self.spatial_deformation = layers.RandomSpatialDeformation(inter_method='nearest')
        self.random_crop = layers.RandomCrop(self.crop_shape)
        self.sample_gmm = layers.SampleConditionalGMM(self.generation_labels)
        self.bias_field = layers.BiasFieldCorruption()
        self.intensity_augmentation = layers.IntensityAugmentation()
        self.convert_labels = layers.ConvertLabels(self.generation_labels, self.output_labels)
        self.gaussian_blur = layers.DynamicGaussianBlur(self.blur_range)
        self.mimic_acquisition = layers.MimicAcquisition(self.atlas_res, self.target_res)
        self.resize_transform = layers.ResizeTransform(None, interp_method='nearest')  # Factor set during forward pass
        self.intensity_normalization = layers.IntensityNormalisation()
    
    def forward(self, labels_input, means_input, stds_input):
        """Forward pass of the Lab2ImModel.
        
        Args:
            labels_input: Input label map tensor [batch, *spatial_dims, 1]
            means_input: Means of the Gaussian Mixture Model [batch, n_labels, n_channels]
            stds_input: Standard deviations of the Gaussian Mixture Model [batch, n_labels, n_channels]
            
        Returns:
            tuple: (image, labels) where image is the generated image and labels are the processed labels
        """
        # Deform labels
        labels = self.spatial_deformation(labels_input)
        
        # Cropping
        if self.crop_shape != self.labels_shape:
            labels = self.random_crop(labels)
        
        # Build synthetic image
        image = self.sample_gmm([labels, means_input, stds_input])
        
        # Apply bias field
        image = self.bias_field(image)
        
        # Intensity augmentation
        image = self.intensity_augmentation(image)
        
        # Reset label values
        labels = self.convert_labels(labels)
        
        # Get data at target resolution (resampling and cropping)
        if self.atlas_res.tolist() != self.target_res.tolist():
            # Get resampling factor
            factor = np.array(self.atlas_res) / np.array(self.target_res)
            
            # Resample image and labels at target resolution
            image = self.gaussian_blur(image)
            image = self.mimic_acquisition(image)
            self.resize_transform.factor = factor
            labels = self.resize_transform(labels)
            
            # Crop image and labels at target shape
            if self.output_shape != labels.shape[1:-1]:
                image = self.random_crop(image, self.output_shape)
                labels = self.random_crop(labels, self.output_shape)
        
        # Normalize image
        image = self.intensity_normalization(image)
        
        return image, labels


def lab2im_model(labels_shape,
                 n_channels,
                 generation_labels,
                 output_labels,
                 atlas_res,
                 target_res,
                 output_shape=None,
                 output_div_by_n=None,
                 blur_range=1.15):
    """Create a PyTorch model to generate images from provided label maps.
    
    This is a convenience function that creates and returns a Lab2ImModel instance.
    
    Args:
        labels_shape: shape of the input label maps. Can be a sequence or a 1d numpy array.
        n_channels: number of channels to be synthesized.
        generation_labels: list of all possible label values in the input label maps.
        output_labels: list of the same length as generation_labels to indicate which values to use.
        atlas_res: resolution of the input label maps.
        target_res: target resolution of the generated images and corresponding label maps.
        output_shape: (optional) desired shape of the output images.
        output_div_by_n: (optional) forces the output shape to be divisible by this value.
        blur_range: (optional) Randomize the standard deviation of the blurring kernels.
        
    Returns:
        Lab2ImModel: PyTorch model for generating images from label maps
    """
    return Lab2ImModel(
        labels_shape=labels_shape,
        n_channels=n_channels,
        generation_labels=generation_labels,
        output_labels=output_labels,
        atlas_res=atlas_res,
        target_res=target_res,
        output_shape=output_shape,
        output_div_by_n=output_div_by_n,
        blur_range=blur_range
    )


def get_shapes(labels_shape, output_shape, atlas_res, target_res, output_div_by_n):
    """Compute the shape of the input and output tensors that will be given to the neural network.
    
    This assumes that the inputs of the network will be cropped to a given shape, and the outputs will be resized to
    another given shape.
    
    Args:
        labels_shape: shape of the input label maps, without batch or channel dimensions.
        output_shape: shape of the outputs, without batch or channel dimensions.
            Can be an int, a sequence or a 1d numpy array.
        atlas_res: resolution of the input label maps.
        target_res: resolution of the outputs.
        output_div_by_n: (optional) forces the output shape to be divisible by this value. It overwrites output_shape
            if necessary. Can be an int, a sequence or a 1d numpy array.
            
    Returns:
        tuple: (crop_shape, output_shape) - the shape of the cropped inputs, and the shape of the outputs.
    """
    # Get cropping shape
    n_dims = len(labels_shape)
    labels_shape = utils.reformat_to_list(labels_shape, length=n_dims)
    atlas_res = utils.reformat_to_list(atlas_res, length=n_dims)
    target_res = utils.reformat_to_list(target_res, length=n_dims)
    crop_shape = labels_shape

    # Get output shape
    if output_shape is not None:  # In this case output_shape overwrites target_res
        output_shape = utils.reformat_to_list(output_shape, length=n_dims)
    elif atlas_res != target_res:  # Here we use target_res to compute the output shape
        output_shape = [int(labels_shape[i] * atlas_res[i] / target_res[i]) for i in range(n_dims)]
    else:  # If we don't resize the inputs, the outputs will have the same shape as the cropped inputs
        output_shape = crop_shape

    # Make sure output shape is divisible by output_div_by_n
    if output_div_by_n is not None:
        output_div_by_n = utils.reformat_to_list(output_div_by_n, length=n_dims)
        tmp_shape = [utils.find_closest_number_divisible_by_m(s, output_div_by_n[i], smaller_ans=False)
                     for (i, s) in enumerate(output_shape)]
        if output_shape != tmp_shape:
            print('output shape {0} not divisible by {1}, changed to {2}'.format(output_shape, output_div_by_n,
                                                                                 tmp_shape))
            output_shape = tmp_shape

    return crop_shape, output_shape